{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTrq6JChhdu4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import PowerTransformer, StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuh65HWfhgrm",
        "outputId": "aded512d-35f8-4a9e-f686-3a474a568270"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1926087617.py:1: DtypeWarning: Columns (20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  data = pd.read_csv('loan_data_2007_2014.csv')\n"
          ]
        }
      ],
      "source": [
        "data = pd.read_csv('loan_data_2007_2014.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2WR8bn_h3aA",
        "outputId": "dd45d861-f7cb-4f4b-a93d-ef86a2da7b50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape setelah drop: (466285, 58)\n"
          ]
        }
      ],
      "source": [
        "total_rows = len(data)\n",
        "\n",
        "missing_summary = data.isnull().sum().reset_index()\n",
        "missing_summary.columns = [\"column\", \"missing_count\"]\n",
        "missing_summary[\"missing_pct\"] = (missing_summary[\"missing_count\"] / total_rows) * 100\n",
        "\n",
        "full_missing_summary = missing_summary[missing_summary[\"missing_count\"] == total_rows]\n",
        "full_missing_cols = full_missing_summary[\"column\"].tolist()\n",
        "\n",
        "data = data.drop(columns=full_missing_cols)\n",
        "\n",
        "print(\"Shape setelah drop:\", data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbwvUitgiBOd",
        "outputId": "650a9bd7-593e-47ed-c606-b2f3f1a7015a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape setelah drop >60% missing: (466285, 55)\n"
          ]
        }
      ],
      "source": [
        "missing_frac = data.isnull().mean()\n",
        "cols_to_drop = missing_frac[missing_frac > 0.6].index\n",
        "data = data.drop(columns=cols_to_drop)\n",
        "print(\"Shape setelah drop >60% missing:\", data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bLmWCT-XtXIT"
      },
      "outputs": [],
      "source": [
        "# === 2. Imputasi missing ===\n",
        "# Numerik â†’ median\n",
        "for col in data.select_dtypes(include=[np.number]).columns:\n",
        "    if data[col].isnull().sum() > 0:\n",
        "        data[col] = data[col].fillna(data[col].median())\n",
        "\n",
        "# Kategorikal â†’ \"Unknown\"\n",
        "for col in data.select_dtypes(include=['object']).columns:\n",
        "    if data[col].isnull().sum() > 0:\n",
        "        data[col] = data[col].fillna(\"Unknown\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9fCm6azJtpB3"
      },
      "outputs": [],
      "source": [
        "# === 3. Tangani outlier (winsorization 1%-99%) ===\n",
        "outlier_cols = [\"annual_inc\", \"dti\", \"revol_bal\", \"loan_amnt\", \"installment\", \"int_rate\"]\n",
        "for col in outlier_cols:\n",
        "    if col in data.columns:\n",
        "        lower, upper = data[col].quantile([0.01, 0.99])\n",
        "        data[col] = np.clip(data[col], lower, upper)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ShV5cG42Kq_G"
      },
      "outputs": [],
      "source": [
        "# === 4. Tangani skewness ===\n",
        "num_cols = data.select_dtypes(include=[np.number]).columns\n",
        "skewness = data[num_cols].skew().sort_values(ascending=False)\n",
        "\n",
        "# Pilih kolom dengan skew > 1\n",
        "high_skew = skewness[skewness > 1].index\n",
        "\n",
        "for col in high_skew:\n",
        "    if (data[col] >= 0).all():\n",
        "        # Gunakan log1p kalau semua nilai positif\n",
        "        data[col+\"_log\"] = np.log1p(data[col])\n",
        "    else:\n",
        "        # Gunakan Yeo-Johnson kalau ada nilai negatif/0\n",
        "        pt = PowerTransformer(method='yeo-johnson')\n",
        "        data[col+\"_trans\"] = pt.fit_transform(data[[col]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nipHqz0gLDi9"
      },
      "outputs": [],
      "source": [
        "redundant_cols = [\"funded_amnt\", \"funded_amnt_inv\"]\n",
        "data = data.drop(columns=[c for c in redundant_cols if c in data.columns])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['target'] = data['loan_status'].apply(lambda x: 1 if x in ['Charged Off', 'Default'] else 0)\n",
        "\n",
        "X = data.drop(columns=['loan_status', 'target'])\n",
        "y = data['target']\n"
      ],
      "metadata": {
        "id": "wLlmXMeI4x_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(\"Train shape:\", X_train.shape)\n",
        "print(\"Test shape:\", X_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kUClN_N5H90",
        "outputId": "d48449ee-bcbe-49bb-de4f-f6e728d012cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (326399, 74)\n",
            "Test shape: (139886, 74)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "num_cols = X_train.select_dtypes(include=[np.number]).columns\n",
        "cat_cols = X_train.select_dtypes(exclude=[np.number]).columns\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('num', StandardScaler(), num_cols),\n",
        "    ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)\n",
        "])\n"
      ],
      "metadata": {
        "id": "KRIBen_m5Idz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5a9beac",
        "outputId": "a4dc4ba6-ffe8-42d0-f01f-87965c3303a0"
      },
      "source": [
        "# Konversi kolom datetime ke format datetime\n",
        "datetime_cols = [\"issue_d\", \"last_pymnt_d\", \"next_pymnt_d\", \"last_credit_pull_d\", \"earliest_cr_line\"]\n",
        "\n",
        "for col in datetime_cols:\n",
        "    if col in data.columns: # Check if column exists\n",
        "        data[col] = pd.to_datetime(data[col], errors=\"coerce\")\n",
        "\n",
        "        # ekstrak bulan (1-12), missing jadi 0\n",
        "        data[col + \"_month\"] = data[col].dt.month.fillna(0).astype(int)\n",
        "    else:\n",
        "        print(f\"Column '{col}' not found in DataFrame.\") # Optional: print a message if column is not found\n",
        "\n",
        "# Drop kolom datetime asli\n",
        "data = data.drop(columns=[c for c in datetime_cols if c in data.columns]) # Drop columns only if they exist\n",
        "\n",
        "print(data.filter(like=\"_month\").head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3539746236.py:6: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  data[col] = pd.to_datetime(data[col], errors=\"coerce\")\n",
            "/tmp/ipython-input-3539746236.py:6: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  data[col] = pd.to_datetime(data[col], errors=\"coerce\")\n",
            "/tmp/ipython-input-3539746236.py:6: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  data[col] = pd.to_datetime(data[col], errors=\"coerce\")\n",
            "/tmp/ipython-input-3539746236.py:6: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  data[col] = pd.to_datetime(data[col], errors=\"coerce\")\n",
            "/tmp/ipython-input-3539746236.py:6: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  data[col] = pd.to_datetime(data[col], errors=\"coerce\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   issue_d_month  last_pymnt_d_month  next_pymnt_d_month  \\\n",
            "0              0                   0                   0   \n",
            "1              0                   0                   0   \n",
            "2              0                   0                   0   \n",
            "3              0                   0                   0   \n",
            "4              0                   0                   0   \n",
            "\n",
            "   last_credit_pull_d_month  earliest_cr_line_month  \n",
            "0                         0                       1  \n",
            "1                         0                       4  \n",
            "2                         0                       0  \n",
            "3                         0                       2  \n",
            "4                         0                       1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fit dan transform data training\n",
        "X_train_transformed = preprocessor.fit_transform(X_train)\n",
        "\n",
        "# transform data testing (pakai fit dari train, bukan fit ulang!)\n",
        "X_test_transformed = preprocessor.transform(X_test)\n",
        "\n",
        "print(\"Shape sebelum preprocessing:\", X_train.shape)\n",
        "print(\"Shape sesudah preprocessing:\", X_train_transformed.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwTSWdpQlc2t",
        "outputId": "c367dbd5-8d37-4f8a-ab9a-fcc75d6f83eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape sebelum preprocessing: (326399, 74)\n",
            "Shape sesudah preprocessing: (326399, 526879)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
        "\n",
        "# === Logistic Regression ===\n",
        "log_reg = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('model', LogisticRegression(max_iter=500, solver='liblinear'))\n",
        "])\n",
        "\n",
        "log_reg.fit(X_train, y_train)\n",
        "y_pred_lr = log_reg.predict(X_test)\n",
        "\n",
        "print(\"=== Logistic Regression ===\")\n",
        "print(confusion_matrix(y_test, y_pred_lr))\n",
        "print(classification_report(y_test, y_pred_lr))\n",
        "print(\"ROC-AUC:\", roc_auc_score(y_test, log_reg.predict_proba(X_test)[:,1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wjnh_9JX-zat",
        "outputId": "aa04de63-b339-4cc8-ea00-74eeea5807c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Logistic Regression ===\n",
            "[[126837     57]\n",
            " [   243  12749]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00    126894\n",
            "           1       1.00      0.98      0.99     12992\n",
            "\n",
            "    accuracy                           1.00    139886\n",
            "   macro avg       1.00      0.99      0.99    139886\n",
            "weighted avg       1.00      1.00      1.00    139886\n",
            "\n",
            "ROC-AUC: 0.9992841058488675\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import classification_report, roc_auc_score # Import roc_auc_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Create a pipeline with the preprocessor and the Decision Tree model\n",
        "dt_pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('model', DecisionTreeClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "# parameter grid\n",
        "param_grid = {\n",
        "    'model__max_depth': [3, 5],\n",
        "    'model__min_samples_split': [2, 5],\n",
        "    'model__min_samples_leaf': [1, 2]\n",
        "}\n",
        "\n",
        "# RandomizedSearchCV (ringan)\n",
        "grid_dt = RandomizedSearchCV(dt_pipeline, param_grid, n_iter=3, cv=2,\n",
        "                             scoring='roc_auc', random_state=42)\n",
        "grid_dt.fit(X_train, y_train)\n",
        "\n",
        "# best estimator\n",
        "best_model = grid_dt.best_estimator_\n",
        "\n",
        "# prediksi\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# evaluasi\n",
        "print(\"Best params:\", grid_dt.best_params_)\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"ROC-AUC:\", roc_auc_score(y_test, grid_dt.best_estimator_.predict_proba(X_test)[:, 1])) # Use grid_dt.best_estimator_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7gzAT0fjclw",
        "outputId": "40e6333e-d918-4e7a-f369-30990747ee67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best params: {'model__min_samples_split': 5, 'model__min_samples_leaf': 1, 'model__max_depth': 5}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99    126894\n",
            "           1       1.00      0.89      0.94     12992\n",
            "\n",
            "    accuracy                           0.99    139886\n",
            "   macro avg       0.99      0.95      0.97    139886\n",
            "weighted avg       0.99      0.99      0.99    139886\n",
            "\n",
            "ROC-AUC: 0.9936041800913349\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "from scipy.stats import randint\n",
        "\n",
        "# --- Random Forest dengan class_weight balanced ---\n",
        "rf = RandomForestClassifier(\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    class_weight=\"balanced\"   # ðŸ”‘ fokus ke kelas minoritas\n",
        ")\n",
        "\n",
        "# Pipeline (preprocessor + model)\n",
        "rf_pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('model', rf)\n",
        "])\n",
        "\n",
        "# --- Parameter distributions ---\n",
        "param_dist = {\n",
        "    'model__n_estimators': randint(100, 200),\n",
        "    'model__max_depth': [10],\n",
        "    'model__min_samples_split': [2, 5, 10],\n",
        "    'model__min_samples_leaf': [1, 2, 4],\n",
        "    'model__max_features': ['sqrt', 'log2']\n",
        "}\n",
        "\n",
        "# --- Randomized Search ---\n",
        "rand_rf = RandomizedSearchCV(\n",
        "    estimator=rf_pipeline,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=3,        # cukup 10 iterasi dulu biar cepat\n",
        "    cv=2,\n",
        "    scoring='roc_auc',\n",
        "    n_jobs=-1,\n",
        "    random_state=42,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# --- Training ---\n",
        "rand_rf.fit(X_train, y_train)\n",
        "\n",
        "# --- Evaluasi ---\n",
        "y_pred = rand_rf.predict(X_test)\n",
        "y_proba = rand_rf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"Best params:\", rand_rf.best_params_)\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWuwP4iYV7js",
        "outputId": "ae12b835-13d1-4275-b313-0229adf5f6ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n",
            "Best params: {'model__max_depth': 10, 'model__max_features': 'sqrt', 'model__min_samples_leaf': 1, 'model__min_samples_split': 10, 'model__n_estimators': 182}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.93      0.96    126894\n",
            "           1       0.56      0.89      0.69     12992\n",
            "\n",
            "    accuracy                           0.93    139886\n",
            "   macro avg       0.77      0.91      0.82    139886\n",
            "weighted avg       0.95      0.93      0.93    139886\n",
            "\n",
            "ROC-AUC: 0.9685889094402209\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# --- Model dasar ---\n",
        "xgb = XGBClassifier(\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    eval_metric=\"logloss\",\n",
        "    use_label_encoder=False\n",
        ")\n",
        "\n",
        "# Pipeline (preprocessing + model)\n",
        "xgb_pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('model', xgb)\n",
        "])\n",
        "\n",
        "# --- Parameter distribusi (dibatasi biar cepat) ---\n",
        "param_dist = {\n",
        "    'model__n_estimators': [100, 200],      # jumlah tree\n",
        "    'model__max_depth': [3, 5, 7],          # kedalaman tree\n",
        "    'model__learning_rate': [0.05, 0.1],    # step size\n",
        "    'model__subsample': [0.8, 1.0],         # sampel data\n",
        "    'model__colsample_bytree': [0.8, 1.0]   # fitur per tree\n",
        "}\n",
        "\n",
        "# --- Randomized Search ---\n",
        "rand_xgb = RandomizedSearchCV(\n",
        "    estimator=xgb_pipeline,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=5,\n",
        "    cv=2,\n",
        "    scoring='roc_auc',\n",
        "    n_jobs=-1,\n",
        "    verbose=1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# --- Training ---\n",
        "rand_xgb.fit(X_train, y_train)\n",
        "\n",
        "# --- Evaluasi ---\n",
        "y_pred = rand_xgb.predict(X_test)\n",
        "y_proba = rand_xgb.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"Best params:\", rand_xgb.best_params_)\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"ROC-AUC:\", roc_auc_score(y_test, y_proba))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szJcaJBZTbUE",
        "outputId": "20cb1f86-d5fe-429f-b2ac-350b159f591d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [14:36:25] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best params: {'model__subsample': 1.0, 'model__n_estimators': 200, 'model__max_depth': 5, 'model__learning_rate': 0.1, 'model__colsample_bytree': 1.0}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00    126894\n",
            "           1       1.00      0.99      0.99     12992\n",
            "\n",
            "    accuracy                           1.00    139886\n",
            "   macro avg       1.00      0.99      1.00    139886\n",
            "weighted avg       1.00      1.00      1.00    139886\n",
            "\n",
            "ROC-AUC: 0.9998598653158088\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "\n",
        "# --- Prediksi train ---\n",
        "y_train_pred = rand_xgb.predict(X_train)\n",
        "y_train_proba = rand_xgb.predict_proba(X_train)[:, 1]\n",
        "\n",
        "# --- Prediksi test ---\n",
        "y_test_pred = rand_xgb.predict(X_test)\n",
        "y_test_proba = rand_xgb.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# --- Evaluasi Train ---\n",
        "print(\"=== Train Performance ===\")\n",
        "print(\"Accuracy:\", accuracy_score(y_train, y_train_pred))\n",
        "print(\"ROC-AUC:\", roc_auc_score(y_train, y_train_proba))\n",
        "\n",
        "# --- Evaluasi Test ---\n",
        "print(\"\\n=== Test Performance ===\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
        "print(\"ROC-AUC:\", roc_auc_score(y_test, y_test_proba))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zhLWtpgq2vj",
        "outputId": "aa504215-b67c-4c23-be42-d50a34091323"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Train Performance ===\n",
            "Accuracy: 0.9993903167595489\n",
            "ROC-AUC: 0.9999886692937211\n",
            "\n",
            "=== Test Performance ===\n",
            "Accuracy: 0.9989991850506841\n",
            "ROC-AUC: 0.9998598653158088\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "def evaluate_model(name, model, X_train, y_train, X_test, y_test):\n",
        "    # Prediksi train\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    y_train_proba = model.predict_proba(X_train)[:, 1]\n",
        "\n",
        "    # Prediksi test\n",
        "    y_test_pred = model.predict(X_test)\n",
        "    y_test_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    return {\n",
        "        \"Model\": name,\n",
        "        \"Train Accuracy\": accuracy_score(y_train, y_train_pred),\n",
        "        \"Test Accuracy\": accuracy_score(y_test, y_test_pred),\n",
        "        \"Train ROC-AUC\": roc_auc_score(y_train, y_train_proba),\n",
        "        \"Test ROC-AUC\": roc_auc_score(y_test, y_test_proba),\n",
        "    }\n",
        "\n",
        "# --- Training models ---\n",
        "results = []\n",
        "\n",
        "# XGBoost\n",
        "results.append(evaluate_model(\"XGBoost\", rand_xgb, X_train, y_train, X_test, y_test))\n",
        "\n",
        "# Random Forest\n",
        "results.append(evaluate_model(\"Random Forest\", rand_rf, X_train, y_train, X_test, y_test))\n",
        "\n",
        "# Logistic Regression\n",
        "results.append(evaluate_model(\"Logistic Regression\", log_reg, X_train, y_train, X_test, y_test))\n",
        "\n",
        "# Decision Tree (tambahan baru)\n",
        "# Create a pipeline for the Decision Tree model\n",
        "dt_pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('model', DecisionTreeClassifier(random_state=42))\n",
        "])\n",
        "dt_pipeline.fit(X_train, y_train) # Train the pipeline\n",
        "results.append(evaluate_model(\"Decision Tree\", dt_pipeline, X_train, y_train, X_test, y_test)) # Evaluate the pipeline\n",
        "\n",
        "# --- DataFrame hasil evaluasi ---\n",
        "df_results = pd.DataFrame(results)\n",
        "print(df_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7QGIi3UtPiS",
        "outputId": "631430ec-666e-459f-de74-d80c573e3385"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 Model  Train Accuracy  Test Accuracy  Train ROC-AUC  \\\n",
            "0              XGBoost        0.999390       0.998999       0.999989   \n",
            "1        Random Forest        0.926348       0.925182       0.970182   \n",
            "2  Logistic Regression        0.998931       0.997855       0.999759   \n",
            "3        Decision Tree        1.000000       0.997426       1.000000   \n",
            "\n",
            "   Test ROC-AUC  \n",
            "0      0.999860  \n",
            "1      0.968589  \n",
            "2      0.999284  \n",
            "3      0.988805  \n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMaS/YueZy1Omai1EFUzo5q"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}